{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddksZY1EpTsb",
        "outputId": "0d330585-c3fe-42e3-af58-25fd6ac87791"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph='Natural language processing (NLP) is an interdisciplinary subfield of computer science and information retrieval. It is primarily concerned with giving computers the ability to support and manipulate human language. It involves processing natural language datasets, such as text corpora or speech corpora, using either rule-based or probabilistic (i.e. statistical and, most recently, neural network-based) machine learning approaches. The goal is a computer capable of \"understanding\"[citation needed] the contents of documents, including the contextual nuances of the language within them. To this end, natural language processing often borrows ideas from theoretical linguistics. The technology can then accurately extract information and insights contained in the documents as well as categorize and organize the documents themselves.'"
      ],
      "metadata": {
        "id": "HRF9uZoZpbQF"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "hICrRRlzpoQp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenization --- convert paragraph into sentences-words\n",
        "nltk.download('punkt')\n",
        "sentences=nltk.sent_tokenize(paragraph)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EpLfLv0pu41",
        "outputId": "0f381473-9de6-495a-b7f3-6bbb43995ce2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_P703kfqD9F",
        "outputId": "1b75dfca-419f-4957-be76-8fe8f2fe1ab0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Natural language processing (NLP) is an interdisciplinary subfield of computer science and information retrieval.', 'It is primarily concerned with giving computers the ability to support and manipulate human language.', 'It involves processing natural language datasets, such as text corpora or speech corpora, using either rule-based or probabilistic (i.e.', 'statistical and, most recently, neural network-based) machine learning approaches.', 'The goal is a computer capable of \"understanding\"[citation needed] the contents of documents, including the contextual nuances of the language within them.', 'To this end, natural language processing often borrows ideas from theoretical linguistics.', 'The technology can then accurately extract information and insights contained in the documents as well as categorize and organize the documents themselves.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer=PorterStemmer()"
      ],
      "metadata": {
        "id": "TkQsjA_lqF9j"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer.stem('thinking')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "PRv-xJ1qqNyG",
        "outputId": "33a05966-dd98-420f-f8a7-e4b11c726cdb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'think'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "bAsjSIXKqPpH"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYhiH9OlqJIU",
        "outputId": "e046ce8c-73cd-43ba-950e-c0c8191a350b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "corpus=[]\n",
        "for i in range(len(sentences)):\n",
        "  review=re.sub('[^a-zA-Z]',' ',sentences[i])\n",
        "  review=review.lower()\n",
        "  review=review.split()\n",
        "  review=[lemmatizer.lemmatize(word) for word in review]\n",
        "  review =\" \".join(review)\n",
        "  corpus.append(review)"
      ],
      "metadata": {
        "id": "nFJA-lMIqhRP"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qvmUAX0qj9m",
        "outputId": "b342be3c-75c9-46a4-bbdc-8320cf15c24c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['natural language processing nlp is an interdisciplinary subfield of computer science and information retrieval',\n",
              " 'it is primarily concerned with giving computer the ability to support and manipulate human language',\n",
              " 'it involves processing natural language datasets such a text corpus or speech corpus using either rule based or probabilistic i e',\n",
              " 'statistical and most recently neural network based machine learning approach',\n",
              " 'the goal is a computer capable of understanding citation needed the content of document including the contextual nuance of the language within them',\n",
              " 'to this end natural language processing often borrows idea from theoretical linguistics',\n",
              " 'the technology can then accurately extract information and insight contained in the document a well a categorize and organize the document themselves']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in corpus:\n",
        "  words=nltk.word_tokenize(i)\n",
        "  for word in words:\n",
        "    if word not in set(stopwords.words('english')):\n",
        "      print(stemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_DuYZLIrwJQ",
        "outputId": "728e0e9e-0c5e-4b00-8183-f35f3703ffcd"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "natur\n",
            "languag\n",
            "process\n",
            "nlp\n",
            "interdisciplinari\n",
            "subfield\n",
            "comput\n",
            "scienc\n",
            "inform\n",
            "retriev\n",
            "primarili\n",
            "concern\n",
            "give\n",
            "comput\n",
            "abil\n",
            "support\n",
            "manipul\n",
            "human\n",
            "languag\n",
            "involv\n",
            "process\n",
            "natur\n",
            "languag\n",
            "dataset\n",
            "text\n",
            "corpu\n",
            "speech\n",
            "corpu\n",
            "use\n",
            "either\n",
            "rule\n",
            "base\n",
            "probabilist\n",
            "e\n",
            "statist\n",
            "recent\n",
            "neural\n",
            "network\n",
            "base\n",
            "machin\n",
            "learn\n",
            "approach\n",
            "goal\n",
            "comput\n",
            "capabl\n",
            "understand\n",
            "citat\n",
            "need\n",
            "content\n",
            "document\n",
            "includ\n",
            "contextu\n",
            "nuanc\n",
            "languag\n",
            "within\n",
            "end\n",
            "natur\n",
            "languag\n",
            "process\n",
            "often\n",
            "borrow\n",
            "idea\n",
            "theoret\n",
            "linguist\n",
            "technolog\n",
            "accur\n",
            "extract\n",
            "inform\n",
            "insight\n",
            "contain\n",
            "document\n",
            "well\n",
            "categor\n",
            "organ\n",
            "document\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in corpus:\n",
        "  words=nltk.word_tokenize(i)\n",
        "  for word in words:\n",
        "    if word not in set(stopwords.words('english')):\n",
        "      print(lemmatizer.lemmatize(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l19_uRxpsSXP",
        "outputId": "50603627-6272-4614-a6eb-4d119ee17235"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "natural\n",
            "language\n",
            "processing\n",
            "nlp\n",
            "interdisciplinary\n",
            "subfield\n",
            "computer\n",
            "science\n",
            "information\n",
            "retrieval\n",
            "primarily\n",
            "concerned\n",
            "giving\n",
            "computer\n",
            "ability\n",
            "support\n",
            "manipulate\n",
            "human\n",
            "language\n",
            "involves\n",
            "processing\n",
            "natural\n",
            "language\n",
            "datasets\n",
            "text\n",
            "corpus\n",
            "speech\n",
            "corpus\n",
            "using\n",
            "either\n",
            "rule\n",
            "based\n",
            "probabilistic\n",
            "e\n",
            "statistical\n",
            "recently\n",
            "neural\n",
            "network\n",
            "based\n",
            "machine\n",
            "learning\n",
            "approach\n",
            "goal\n",
            "computer\n",
            "capable\n",
            "understanding\n",
            "citation\n",
            "needed\n",
            "content\n",
            "document\n",
            "including\n",
            "contextual\n",
            "nuance\n",
            "language\n",
            "within\n",
            "end\n",
            "natural\n",
            "language\n",
            "processing\n",
            "often\n",
            "borrows\n",
            "idea\n",
            "theoretical\n",
            "linguistics\n",
            "technology\n",
            "accurately\n",
            "extract\n",
            "information\n",
            "insight\n",
            "contained\n",
            "document\n",
            "well\n",
            "categorize\n",
            "organize\n",
            "document\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Bag of words\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv=CountVectorizer(binary=True,ngram_range=(2,3))"
      ],
      "metadata": {
        "id": "0Jd5xgBzqu_h"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=cv.fit_transform(corpus)"
      ],
      "metadata": {
        "id": "u1PJ8S06q9Pe"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv.vocabulary_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jm4I77V6rBho",
        "outputId": "e9f3d2cc-a967-4903-ed7a-1f93750bdf37"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'natural language': 107,\n",
              " 'language processing': 95,\n",
              " 'processing nlp': 139,\n",
              " 'nlp is': 116,\n",
              " 'is an': 83,\n",
              " 'an interdisciplinary': 4,\n",
              " 'interdisciplinary subfield': 79,\n",
              " 'subfield of': 153,\n",
              " 'of computer': 120,\n",
              " 'computer science': 32,\n",
              " 'science and': 147,\n",
              " 'and information': 6,\n",
              " 'information retrieval': 76,\n",
              " 'natural language processing': 109,\n",
              " 'language processing nlp': 96,\n",
              " 'processing nlp is': 140,\n",
              " 'nlp is an': 117,\n",
              " 'is an interdisciplinary': 84,\n",
              " 'an interdisciplinary subfield': 5,\n",
              " 'interdisciplinary subfield of': 80,\n",
              " 'subfield of computer': 154,\n",
              " 'of computer science': 121,\n",
              " 'computer science and': 33,\n",
              " 'science and information': 148,\n",
              " 'and information retrieval': 7,\n",
              " 'it is': 91,\n",
              " 'is primarily': 87,\n",
              " 'primarily concerned': 135,\n",
              " 'concerned with': 36,\n",
              " 'with giving': 193,\n",
              " 'giving computer': 63,\n",
              " 'computer the': 34,\n",
              " 'the ability': 163,\n",
              " 'ability to': 0,\n",
              " 'to support': 183,\n",
              " 'support and': 157,\n",
              " 'and manipulate': 10,\n",
              " 'manipulate human': 103,\n",
              " 'human language': 67,\n",
              " 'it is primarily': 92,\n",
              " 'is primarily concerned': 88,\n",
              " 'primarily concerned with': 136,\n",
              " 'concerned with giving': 37,\n",
              " 'with giving computer': 194,\n",
              " 'giving computer the': 64,\n",
              " 'computer the ability': 35,\n",
              " 'the ability to': 164,\n",
              " 'ability to support': 1,\n",
              " 'to support and': 184,\n",
              " 'support and manipulate': 158,\n",
              " 'and manipulate human': 11,\n",
              " 'manipulate human language': 104,\n",
              " 'it involves': 89,\n",
              " 'involves processing': 81,\n",
              " 'processing natural': 137,\n",
              " 'language datasets': 93,\n",
              " 'datasets such': 48,\n",
              " 'such text': 155,\n",
              " 'text corpus': 161,\n",
              " 'corpus or': 44,\n",
              " 'or speech': 131,\n",
              " 'speech corpus': 149,\n",
              " 'corpus using': 46,\n",
              " 'using either': 189,\n",
              " 'either rule': 55,\n",
              " 'rule based': 145,\n",
              " 'based or': 18,\n",
              " 'or probabilistic': 130,\n",
              " 'it involves processing': 90,\n",
              " 'involves processing natural': 82,\n",
              " 'processing natural language': 138,\n",
              " 'natural language datasets': 108,\n",
              " 'language datasets such': 94,\n",
              " 'datasets such text': 49,\n",
              " 'such text corpus': 156,\n",
              " 'text corpus or': 162,\n",
              " 'corpus or speech': 45,\n",
              " 'or speech corpus': 132,\n",
              " 'speech corpus using': 150,\n",
              " 'corpus using either': 47,\n",
              " 'using either rule': 190,\n",
              " 'either rule based': 56,\n",
              " 'rule based or': 146,\n",
              " 'based or probabilistic': 19,\n",
              " 'statistical and': 151,\n",
              " 'and most': 12,\n",
              " 'most recently': 105,\n",
              " 'recently neural': 143,\n",
              " 'neural network': 114,\n",
              " 'network based': 112,\n",
              " 'based machine': 16,\n",
              " 'machine learning': 101,\n",
              " 'learning approach': 100,\n",
              " 'statistical and most': 152,\n",
              " 'and most recently': 13,\n",
              " 'most recently neural': 106,\n",
              " 'recently neural network': 144,\n",
              " 'neural network based': 115,\n",
              " 'network based machine': 113,\n",
              " 'based machine learning': 17,\n",
              " 'machine learning approach': 102,\n",
              " 'the goal': 172,\n",
              " 'goal is': 65,\n",
              " 'is computer': 85,\n",
              " 'computer capable': 30,\n",
              " 'capable of': 24,\n",
              " 'of understanding': 126,\n",
              " 'understanding citation': 187,\n",
              " 'citation needed': 28,\n",
              " 'needed the': 110,\n",
              " 'the content': 165,\n",
              " 'content of': 40,\n",
              " 'of document': 122,\n",
              " 'document including': 50,\n",
              " 'including the': 72,\n",
              " 'the contextual': 167,\n",
              " 'contextual nuance': 42,\n",
              " 'nuance of': 118,\n",
              " 'of the': 124,\n",
              " 'the language': 174,\n",
              " 'language within': 98,\n",
              " 'within them': 195,\n",
              " 'the goal is': 173,\n",
              " 'goal is computer': 66,\n",
              " 'is computer capable': 86,\n",
              " 'computer capable of': 31,\n",
              " 'capable of understanding': 25,\n",
              " 'of understanding citation': 127,\n",
              " 'understanding citation needed': 188,\n",
              " 'citation needed the': 29,\n",
              " 'needed the content': 111,\n",
              " 'the content of': 166,\n",
              " 'content of document': 41,\n",
              " 'of document including': 123,\n",
              " 'document including the': 51,\n",
              " 'including the contextual': 73,\n",
              " 'the contextual nuance': 168,\n",
              " 'contextual nuance of': 43,\n",
              " 'nuance of the': 119,\n",
              " 'of the language': 125,\n",
              " 'the language within': 175,\n",
              " 'language within them': 99,\n",
              " 'to this': 185,\n",
              " 'this end': 181,\n",
              " 'end natural': 57,\n",
              " 'processing often': 141,\n",
              " 'often borrows': 128,\n",
              " 'borrows idea': 20,\n",
              " 'idea from': 68,\n",
              " 'from theoretical': 61,\n",
              " 'theoretical linguistics': 180,\n",
              " 'to this end': 186,\n",
              " 'this end natural': 182,\n",
              " 'end natural language': 58,\n",
              " 'language processing often': 97,\n",
              " 'processing often borrows': 142,\n",
              " 'often borrows idea': 129,\n",
              " 'borrows idea from': 21,\n",
              " 'idea from theoretical': 69,\n",
              " 'from theoretical linguistics': 62,\n",
              " 'the technology': 176,\n",
              " 'technology can': 159,\n",
              " 'can then': 22,\n",
              " 'then accurately': 178,\n",
              " 'accurately extract': 2,\n",
              " 'extract information': 59,\n",
              " 'information and': 74,\n",
              " 'and insight': 8,\n",
              " 'insight contained': 77,\n",
              " 'contained in': 38,\n",
              " 'in the': 70,\n",
              " 'the document': 169,\n",
              " 'document well': 53,\n",
              " 'well categorize': 191,\n",
              " 'categorize and': 26,\n",
              " 'and organize': 14,\n",
              " 'organize the': 133,\n",
              " 'document themselves': 52,\n",
              " 'the technology can': 177,\n",
              " 'technology can then': 160,\n",
              " 'can then accurately': 23,\n",
              " 'then accurately extract': 179,\n",
              " 'accurately extract information': 3,\n",
              " 'extract information and': 60,\n",
              " 'information and insight': 75,\n",
              " 'and insight contained': 9,\n",
              " 'insight contained in': 78,\n",
              " 'contained in the': 39,\n",
              " 'in the document': 71,\n",
              " 'the document well': 171,\n",
              " 'document well categorize': 54,\n",
              " 'well categorize and': 192,\n",
              " 'categorize and organize': 27,\n",
              " 'and organize the': 15,\n",
              " 'organize the document': 134,\n",
              " 'the document themselves': 170}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## TFIDF\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "cv=TfidfVectorizer()\n",
        "X=cv.fit_transform(corpus)"
      ],
      "metadata": {
        "id": "GoFRZZwbrF41"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "LUAadl6brZLv",
        "outputId": "703b7f54-0fd1-4d4f-f1a4-6bac7a66ba93"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'natural language processing nlp is an interdisciplinary subfield of computer science and information retrieval'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[0].toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NvtW3XTrbX0",
        "outputId": "224838b3-5fde-48b8-db35-39ffe2ccbb19"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.31524446, 0.19419671, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.22367537, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.26167998,\n",
              "        0.        , 0.31524446, 0.        , 0.22367537, 0.        ,\n",
              "        0.17011088, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.22367537, 0.        , 0.        , 0.        ,\n",
              "        0.31524446, 0.        , 0.26167998, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.22367537, 0.        ,\n",
              "        0.31524446, 0.        , 0.31524446, 0.        , 0.        ,\n",
              "        0.31524446, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8_M4NFntrcjZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}